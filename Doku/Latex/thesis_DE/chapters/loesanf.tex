\chapter[Lösungsauswahl anhand der Anforderungen]{Lösungsauswahl anhand der Anforderungen}
\label{cha:loesungsauswahl}

\section{Framework}
\label{sec:framework}

Als Framework für die gewünschte Umsetzung wird Hadoop genutzt. Die Kriterien die für Hadoop sprechen sind: gute Skalierbarkeit, Bekanntheit, sowie eine solide Grundausstattung, die bei der Installation des Frameworks bereits enthalten ist. Dazu gehören die bereits genannten Bausteine HDFS, Map-Reduce und YARN. Mit diesen zugehörigen Komponenten ist eine Umsetzung des gewünschten Use-Case bereits ohne zusätzliche Installation von Komponenten umsetzbar. Des Weiteren besitzt Hadoop aufgrund seiner Bekanntheit ein großes Ökosystem mit zahlreichen Technologien, die sich bei Bedarf ohne großen Aufwand hinzufügen lassen. Hadoop ist durch die Verwendung des Map-Reduce Verfahrens auf textbasierte Eingabequellen in Form von Text-Files spezialisiert, was für unseren Use-Case von großer Bedeutung ist, da die Webserver Log-Files in Form von Text-Files vorliegen.

Spark im Vergleich dazu, hat seine Vorteile in der Verarbeitung von Datenströmen. Zudem übernimmt Spark nur ein kleiner Bestandteil der Funktionen die Hadoop als Framwork übernimmt. Spark kann nicht alleine betrieben werden, sondern braucht als Basis ein Hadoop Cluster. Spark wäre somit eine Alternative zur Software, die auf dem Cluster verteilt arbeitet und das Cluster organisiert. Damit müssten bei der Verwendung von Spark noch zusätzliche Komponenten installiert werden, die bei Hadoop bereits enthalten sind. Zusätzlich werden bei der Installation von Spark Technologien mitgeliefert, die bei unserem Use-Case keinen Gebrauch finden würden, wie zum Beispiel machine learning. 

\pagebreak

\section{Datenbank}
\label{sec:datenbank}

Aufgrund der vorigen Wahl des Frameworks wird als Datenbank HBase verwendet. HBase zeigt bereits durch ihren ausgeschriebenen Namen "Hadoop Database" die enge Verknüpfung mit Hadoop. Wie bereits im Schaubild Hadoop-Ökosystem \ref{img:hadoopecosystem} gezeigt wurde, gehört HBase zur großen Sammlung an Technologien, die mit Hadoop bequem verknüpfbar sind. Dadurch lässt sich HBase von Haus aus mit Hadoop kombinieren und auf dem bereits vorhandenen Hadoop Clusters verteilt installieren. Zudem bietet der Aufbau der spaltenorientierten NoSQL-Datenbank mit der Besonderheit, dass Datensätze unabhängig voneinander unterschiedliche Spaltenzahlen haben können, einen Vorteil bei der Speicherung der extrahierten Daten aus den Webserver-Log Files. 

Cassandra unterscheidet sich von ihrer Funktionalität her sehr wenig bis gar nicht von HBase. Der einzige ausschlaggebende Unterschied liegt darin, dass Cassandra zusammen mit Spark verwendet wird und weniger gut mit Hadoop harmoniert.

\section{Virtualisierungssoftware}
\label{sec:virtsoft}

Für den Prototyp zur Analyse von Log-Files wird Docker als Virtualisierungssoftware eingesetzt, aufgrund des äußerst sparsamen Umgang mit Ressourcen sowie den kurzen Startzeiten. Docker-Container weisen eine kurze Startzeit auf, da sie nicht erst das Betriebssystem, Ressourcen und Bibliotheken laden müssen, sondern direkt auf die Komponenten und Daten der Betriebsumgebung zugreifen können. 

Somit erfüllt Docker alle Anforderungen des Projekts.